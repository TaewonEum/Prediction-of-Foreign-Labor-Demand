{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b7cb147-bcfa-4fe4-8c44-148a39633b26",
   "metadata": {},
   "source": [
    "# LightGBM Regression 목차\n",
    "\n",
    "## 0. 분석 환경 확인\n",
    "\n",
    "## 1. 패키지 로드\n",
    "\n",
    "## 2. 데이터 로드\n",
    "\n",
    "## 3. 분포 확인 및 이상치 제거\n",
    "\n",
    "## 4. 데이터 분할\n",
    "\n",
    "## 5. 정규화 및 라벨 인코딩\n",
    "\n",
    "## 6. 모델 적용\n",
    "\n",
    "### 6.1 초기 모델 적용\n",
    "\n",
    "### 6.2 파라마터 튜닝-1\n",
    "\n",
    "### 6.3 파리미터 튜닝-2\n",
    "\n",
    "## 7. 결과 활용 및 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eea99a-e667-41bd-b85a-a135aa385352",
   "metadata": {},
   "source": [
    "## 0.분석 환경 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd57727-fe62-46f9-a8ff-0cee5f04bfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\법무부_파이썬분석\\시연관련데이터\n",
      "C:\\Users\\user\\Desktop\\법무부_파이썬분석\\시연관련데이터\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "#현재 디렉토리 확인\n",
    "print(os.getcwd())\n",
    "# 분석 디렉토리로 이동\n",
    "os.chdir('C:\\\\Users\\\\user\\\\Desktop\\\\법무부_파이썬분석\\\\시연관련데이터')\n",
    "print(os.getcwd())\n",
    "\n",
    "#시드고정\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6874e74-7c7b-4f73-8c9f-ae3de566643b",
   "metadata": {},
   "source": [
    "# MAE & mse & Rmse & Rmspe\n",
    "\n",
    "- MAE=실제값과 예측값 사이의 절대값의 평균=> 크면 클 수록 예측력이 낮은 것\n",
    "- MSE=실제값과 예측값 사이의 차이를 제곱한 평균\n",
    "- RMSE=MSE에 루트를 취한 값\n",
    "- RMSPE=예측 오차를 실제값으로 나눈후 제곱하여 평균을 측정한 제곱근임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48ea0f26-0e68-4b4b-9150-be8205b0c786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능지표 추출\n",
    "def Evaluation_metric(actual,pred):\n",
    "    print(f'MAE: {round(mean_absolute_error(actual,pred),2)}')\n",
    "    print(f'MSE: {round(mean_squared_error(actual,pred),2)}')\n",
    "    print(f'RMSE: {round(sqrt(mean_squared_error(actual,pred)),2)}')\n",
    "    #print(f'RMSPE: {round(sqrt(mean_squared_error(actual,pred))/np.mean(actual)*100,2)}%')\n",
    "    print(f'RMSPE: {round(np.sqrt(np.mean(((actual - pred) / actual) ** 2)) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb09ccb-d9b3-4cd8-9f79-94bedd7aa228",
   "metadata": {},
   "source": [
    "## 1. 패키지 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3276be07-38de-481d-87d7-ebc29c5fcc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "sns.set(font=\"Malgun Gothic\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad09e1-f89b-43de-a320-bfff6d9a8adb",
   "metadata": {},
   "source": [
    "# 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d15d0e-3227-43eb-a9c8-cde7ef9e0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Valid, Test Split용 데이터\n",
    "data=pd.read_csv(os.listdir()[13],encoding='EUC-KR')\n",
    "# 지표 확인용 데20\n",
    "data_real=pd.read_csv(os.listdir()[13],encoding='EUC-KR')\n",
    "# 배정신청인원 0명 제거\n",
    "data=data.query('합계!=0')\n",
    "#필요 컬럼 추출\n",
    "selected_columns_1=['구분','합계', '작물 종류','농지면적(실제경작)','전년대비농경체증감률','고령농경체비율','전년도이탈인원','전년도활용여부']\n",
    "selected_columns_2=['비고', '지자체명_시도', '지자체명_시군구', '구분', '농업경영체','합계', '작물 종류','농지면적(실제경작)','전년대비농경체증감률','고령농경체비율','전년도이탈인원','전년도활용여부'] #원본 데이터 컬럼\n",
    "data=data[selected_columns_1]\n",
    "data_real=data_real[selected_columns_2]\n",
    "# 농지면적(실제경작) 컬럼명 변경\n",
    "data.rename(columns={'농지면적(실제경작)':'농지면적','작물 종류':'작물종류'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bde231-7e96-4ced-9a73-4f006325c7af",
   "metadata": {},
   "source": [
    "# 3. 이상치 제거: 농지 면적, 합계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d83050-408c-4ec1-8a7a-b7d50a58c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.query('0.04<농지면적<2.5')\n",
    "data=data.query('합계<11')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89e7a6-dcc3-4092-8994-e0c9323c9f4c",
   "metadata": {},
   "source": [
    "# 4. 데이터 분할 Train, Valid, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89b263f7-bd65-444b-a98f-264bb9ffa7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작물 종류 기준 층화 추출 Train Test 비율 8:2\n",
    "X=data.drop(columns=['합계']) #독립변수 Set\n",
    "Y=data['합계'] #Target 변수 set\n",
    "\n",
    "# Train, Test 분할\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,stratify=X['작물종류'],random_state=42)\n",
    "\n",
    "# 2차 Train, Validation 분할\n",
    "X_train, X_valid, Y_train, Y_valid=train_test_split(X_train,Y_train,test_size=0.2,stratify=X_train['작물종류'],random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a35d3e-5491-4b92-8d1c-cb039e03daf9",
   "metadata": {},
   "source": [
    "# 5. 연속형 변수 정규화 & 범주형 변수 라벨 인코딩 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "100e66d4-1b3b-452f-b4f5-641f48b64623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속형 변수 정규화\n",
    "min_max_scaler=MinMaxScaler()\n",
    "for i in X_train.columns:\n",
    "    if (X_train[i].dtypes!='object'):\n",
    "        X_train[i]=min_max_scaler.fit_transform(X_train[[i]])\n",
    "        X_valid[i]=min_max_scaler.transform(X_valid[[i]])\n",
    "        X_test[i]=min_max_scaler.transform(X_test[[i]])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c1dbe6-0673-4efe-907f-183411eb2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 라벨 인코딩\n",
    "label_encoder=LabelEncoder()\n",
    "for i in X_train.columns:\n",
    "    if X_train[i].dtypes=='object':\n",
    "        X_train[i]=label_encoder.fit_transform(X_train[i])\n",
    "        X_valid[i]=label_encoder.transform(X_valid[i])\n",
    "        X_test[i]=label_encoder.transform(X_test[i])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd5876-ac45-4e04-8274-7910ad789e75",
   "metadata": {},
   "source": [
    "# 6. 모델 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee1d72-3cd5-4a48-ab28-bb7f2f0789bf",
   "metadata": {},
   "source": [
    "- 주요 파라미터 설명\n",
    "\n",
    "- num_leaves: 트리가 가질 수 있는 최대 잎의 수\n",
    "\n",
    "- max_depth: 최대 트리 깊이\n",
    "\n",
    "- learning_rate: 학습률\n",
    "\n",
    "- n_estimator: 생성할 부스팅 트리 개수\n",
    "\n",
    "- subsample: 훈련데이터 샘플링 비율\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "- 초기 파라미터\n",
    "- model_reg=LGBMRegressor(n_jobs=-1,n_estimators=150,learning_rate=0.05,random_state=42,objective='regression')\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8cdd0e-289c-4ae4-b8e0-791d0322c694",
   "metadata": {},
   "source": [
    "# 6.1 초기 기본 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e00e6b92-3426-4aad-8dd5-64e4c5bfeb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 447\n",
      "[LightGBM] [Info] Number of data points in the train set: 7784, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 3.371274\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE: 1.25\n",
      "MSE: 2.97\n",
      "RMSE: 1.72\n",
      "RMSPE: 125.02%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE: 8.2\n",
      "MSE: 140.0\n",
      "RMSE: 11.83\n",
      "RMSPE: 21.14%\n"
     ]
    }
   ],
   "source": [
    "model_reg=LGBMRegressor(n_jobs=-1,n_estimators=200,learning_rate=0.05,random_state=42,objective='regression')\n",
    "model_reg.fit(X_train,Y_train)\n",
    "pred=model_reg.predict(X_test)\n",
    "# 인원 수 예측이기에 예측된 결과에 반올림 적용\n",
    "pred=pd.DataFrame(pred,columns=['예측값'])\n",
    "pred['예측값']=round(pred['예측값'],0)\n",
    "pred\n",
    "print('-'*100)\n",
    "Evaluation_metric(Y_test,pred=pred['예측값'])\n",
    "print('-'*100)\n",
    "# Test data Set\n",
    "test_index=X_test.index.tolist()\n",
    "data_test=data_real.loc[test_index]\n",
    "data_test=data_test.reset_index()\n",
    "data_test.drop(columns=['index'],inplace=True)\n",
    "data_test['predict']=pred\n",
    "result=data_test.groupby(['지자체명_시도','지자체명_시군구'])[['합계','predict']].sum().reset_index()\n",
    "result_1=result.query('합계>10')\n",
    "Evaluation_metric(result_1['합계'],pred=result_1['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379002d5-a73e-41d6-b1b5-9e0c660747a3",
   "metadata": {},
   "source": [
    "# 6.2 파라미터 튜닝-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "730a8b9d-ef6b-4884-b395-12e08ffcb873",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | n_esti... | subsample |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m3.564    \u001b[0m | \u001b[0m0.04871  \u001b[0m | \u001b[0m249.3    \u001b[0m | \u001b[0m0.8491   \u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m3.607    \u001b[0m | \u001b[95m0.05269  \u001b[0m | \u001b[95m253.3    \u001b[0m | \u001b[95m0.8043   \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m3.587    \u001b[0m | \u001b[0m0.04519  \u001b[0m | \u001b[0m296.2    \u001b[0m | \u001b[0m0.9757   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m3.606    \u001b[0m | \u001b[0m0.05796  \u001b[0m | \u001b[0m243.0    \u001b[0m | \u001b[0m0.9897   \u001b[0m |\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m3.647    \u001b[0m | \u001b[95m0.05598  \u001b[0m | \u001b[95m286.0    \u001b[0m | \u001b[95m0.8297   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m3.57     \u001b[0m | \u001b[0m0.0585   \u001b[0m | \u001b[0m215.5    \u001b[0m | \u001b[0m0.8363   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m3.535    \u001b[0m | \u001b[0m0.04612  \u001b[0m | \u001b[0m205.2    \u001b[0m | \u001b[0m0.9704   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m3.508    \u001b[0m | \u001b[0m0.0343   \u001b[0m | \u001b[0m244.4    \u001b[0m | \u001b[0m0.9011   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m3.616    \u001b[0m | \u001b[0m0.0562   \u001b[0m | \u001b[0m261.9    \u001b[0m | \u001b[0m0.8647   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m3.534    \u001b[0m | \u001b[0m0.04116  \u001b[0m | \u001b[0m216.7    \u001b[0m | \u001b[0m0.8709   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m3.531    \u001b[0m | \u001b[0m0.04242  \u001b[0m | \u001b[0m240.5    \u001b[0m | \u001b[0m0.9798   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m3.514    \u001b[0m | \u001b[0m0.03312  \u001b[0m | \u001b[0m253.3    \u001b[0m | \u001b[0m0.8008   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m3.622    \u001b[0m | \u001b[0m0.05492  \u001b[0m | \u001b[0m272.8    \u001b[0m | \u001b[0m0.9797   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m3.542    \u001b[0m | \u001b[0m0.03749  \u001b[0m | \u001b[0m281.0    \u001b[0m | \u001b[0m0.9303   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m3.587    \u001b[0m | \u001b[0m0.05122  \u001b[0m | \u001b[0m251.4    \u001b[0m | \u001b[0m0.9462   \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m3.539    \u001b[0m | \u001b[0m0.04122  \u001b[0m | \u001b[0m238.8    \u001b[0m | \u001b[0m0.8911   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m3.551    \u001b[0m | \u001b[0m0.04501  \u001b[0m | \u001b[0m226.6    \u001b[0m | \u001b[0m0.8995   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m3.567    \u001b[0m | \u001b[0m0.03818  \u001b[0m | \u001b[0m291.2    \u001b[0m | \u001b[0m0.9168   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m3.516    \u001b[0m | \u001b[0m0.03314  \u001b[0m | \u001b[0m246.7    \u001b[0m | \u001b[0m0.8512   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m3.488    \u001b[0m | \u001b[0m0.03796  \u001b[0m | \u001b[0m204.6    \u001b[0m | \u001b[0m0.8685   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m3.617    \u001b[0m | \u001b[0m0.05833  \u001b[0m | \u001b[0m255.9    \u001b[0m | \u001b[0m0.842    \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m3.576    \u001b[0m | \u001b[0m0.04964  \u001b[0m | \u001b[0m243.8    \u001b[0m | \u001b[0m0.9505   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m3.586    \u001b[0m | \u001b[0m0.04206  \u001b[0m | \u001b[0m285.2    \u001b[0m | \u001b[0m0.8737   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m3.565    \u001b[0m | \u001b[0m0.04645  \u001b[0m | \u001b[0m249.2    \u001b[0m | \u001b[0m0.865    \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m3.624    \u001b[0m | \u001b[0m0.05685  \u001b[0m | \u001b[0m245.3    \u001b[0m | \u001b[0m0.977    \u001b[0m |\n",
      "=============================================================\n",
      "최종 파라미터는 {'subsample': 0.8685010960741302, 'n_estimators': 205, 'learning_rate': 0.03796262468430274}입니다\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000217 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 447\n",
      "[LightGBM] [Info] Number of data points in the train set: 7784, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 3.371274\n",
      "농업경영체별 평가지표 결과\n",
      "MAE: 1.27\n",
      "MSE: 3.02\n",
      "RMSE: 1.74\n",
      "RMSPE: 124.12%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "배정신청인원 10명 이상 시군구 단위 평가지표\n",
      "MAE: 8.64\n",
      "MSE: 159.53\n",
      "RMSE: 12.63\n",
      "RMSPE: 21.95%\n"
     ]
    }
   ],
   "source": [
    "# 목적 함수 정의\n",
    "results = {\n",
    "    'subsample': [],\n",
    "    'n_estimators': [],\n",
    "    'learning_rate': [],\n",
    "    'target': []  # 최적화 결과인 target 값 저장\n",
    "}\n",
    "\n",
    "def xgb_cv(subsample, n_estimators, learning_rate):\n",
    "    params = {\n",
    "        'subsample': subsample,\n",
    "        'n_estimators': int(n_estimators),\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_jobs':-1,\n",
    "        'objective':'regression',\n",
    "        'verbosity':0\n",
    "    }\n",
    "    \n",
    "    # XGBoost Regressor 모델 초기화\n",
    "    model_reg = LGBMRegressor(**params)\n",
    "    \n",
    "    #model Train 학습\n",
    "    model_reg.fit(X_train,Y_train)\n",
    "    #model validation\n",
    "    scores = -cross_val_score(model_reg, X_valid, Y_valid, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "    results['subsample'].append(subsample)\n",
    "    results['n_estimators'].append(n_estimators)\n",
    "    results['learning_rate'].append(learning_rate)\n",
    "    results['target'].append(scores)\n",
    "    return scores\n",
    "\n",
    "# Bayesian Optimization 수행\n",
    "xgbBO = BayesianOptimization(\n",
    "    xgb_cv,\n",
    "    {'subsample': (0.80, 1.0),\n",
    "     'n_estimators': (200, 300),\n",
    "     'learning_rate': (0.03,0.06)}\n",
    ")\n",
    "\n",
    "# 최적화\n",
    "xgbBO.maximize(init_points=10, n_iter=15)\n",
    "\n",
    "idx_of_min=results['target'].index(min(results['target']))\n",
    "min_pam={}\n",
    "for key,value in results.items():\n",
    "    if key=='target':\n",
    "        pass\n",
    "    else:\n",
    "        if (key=='max_depth') or (key=='n_estimators'):\n",
    "            min_pam[key]=int(round(value[idx_of_min],0))\n",
    "        else:\n",
    "            min_pam[key]=value[idx_of_min]\n",
    "            \n",
    "print(f'최종 파라미터는 {min_pam}입니다')\n",
    "\n",
    "model_reg = LGBMRegressor(**min_pam)\n",
    "model_reg.fit(X_train,Y_train)\n",
    "\n",
    "#예측값 \n",
    "pred=model_reg.predict(X_test)\n",
    "# 인원 수 예측이기에 예측된 결과에 반올림 적용\n",
    "pred=pd.DataFrame(pred,columns=['예측값'])\n",
    "#반올림\n",
    "pred['예측값']=round(pred['예측값'],0)\n",
    "#평가지표\n",
    "print('농업경영체별 평가지표 결과')\n",
    "Evaluation_metric(Y_test,pred=pred['예측값'])\n",
    "print('-'*100)\n",
    "\n",
    "test_index=X_test.index.tolist()\n",
    "data_test=data_real.loc[test_index]\n",
    "data_test=data_test.reset_index()\n",
    "data_test.drop(columns=['index'],inplace=True)\n",
    "#예측값\n",
    "data_test['predict']=pred\n",
    "result=data_test.groupby(['지자체명_시도','지자체명_시군구'])[['합계','predict']].sum().reset_index()\n",
    "result_1=result.query('합계>10')\n",
    "print('배정신청인원 10명 이상 시군구 단위 평가지표')\n",
    "Evaluation_metric(result_1['합계'],pred=result_1['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e38274-f942-4ef5-82ea-7c02660f4b91",
   "metadata": {},
   "source": [
    "# 6.2 파라미터 튜닝-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085b7136-45c8-490b-bd80-fc252c9171ed",
   "metadata": {},
   "source": [
    "파라미터 튜닝 코드\n",
    "\n",
    "- optuna.trial.Trial.suggest_categorical() : 리스트 범위 내에서 값을 선택한다.\n",
    "- optuna.trial.Trial.suggest_int() : 범위 내에서 정수형 값을 선택한다.\n",
    "- optuna.trial.Trial.suggest_float() : 범위 내에서 소수형 값을 선택한다.\n",
    "- optuna.trial.Trial.suggest_uniform() : 범위 내에서 균일분포 값을 선택한다.\n",
    "- optuna.trial.Trial.suggest_discrete_uniform() : 범위 내에서 이산 균일분포 값을 선택한다.\n",
    "- optuna.trial.Trial.suggest_loguniform() : 범위 내에서 로그 함수 값을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eba89e45-f2df-4196-82b7-918be366fcae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 13:05:12,435] A new study created in memory with name: no-name-6095882e-3d18-4bb9-a036-3d96e8c038c5\n",
      "[I 2023-12-07 13:05:12,777] Trial 0 finished with value: 1.3181706590830504 and parameters: {'subsample': 0.95, 'n_estimators': 390, 'learning_rate': 0.04002166881452713}. Best is trial 0 with value: 1.3181706590830504.\n",
      "[I 2023-12-07 13:05:12,898] Trial 1 finished with value: 1.3163592894946137 and parameters: {'subsample': 0.9, 'n_estimators': 234, 'learning_rate': 0.049716258549278775}. Best is trial 1 with value: 1.3163592894946137.\n",
      "[I 2023-12-07 13:05:13,072] Trial 2 finished with value: 1.320132958973618 and parameters: {'subsample': 0.9, 'n_estimators': 282, 'learning_rate': 0.04627543106210828}. Best is trial 1 with value: 1.3163592894946137.\n",
      "[I 2023-12-07 13:05:13,246] Trial 3 finished with value: 1.3153045635472114 and parameters: {'subsample': 0.85, 'n_estimators': 323, 'learning_rate': 0.04672077908831163}. Best is trial 3 with value: 1.3153045635472114.\n",
      "[I 2023-12-07 13:05:13,474] Trial 4 finished with value: 1.3197895533673594 and parameters: {'subsample': 0.9, 'n_estimators': 378, 'learning_rate': 0.042933228710860326}. Best is trial 3 with value: 1.3153045635472114.\n",
      "[I 2023-12-07 13:05:13,787] Trial 5 finished with value: 1.3193298904976685 and parameters: {'subsample': 0.85, 'n_estimators': 375, 'learning_rate': 0.042897182211693446}. Best is trial 3 with value: 1.3153045635472114.\n",
      "[I 2023-12-07 13:05:13,948] Trial 6 finished with value: 1.3200516074952995 and parameters: {'subsample': 0.8, 'n_estimators': 287, 'learning_rate': 0.030726661267643222}. Best is trial 3 with value: 1.3153045635472114.\n",
      "[I 2023-12-07 13:05:14,105] Trial 7 finished with value: 1.3204656306344293 and parameters: {'subsample': 0.9, 'n_estimators': 257, 'learning_rate': 0.04576610701747107}. Best is trial 3 with value: 1.3153045635472114.\n",
      "[I 2023-12-07 13:05:14,250] Trial 8 finished with value: 1.320060724726572 and parameters: {'subsample': 0.9, 'n_estimators': 272, 'learning_rate': 0.039895650461512375}. Best is trial 3 with value: 1.3153045635472114.\n",
      "[I 2023-12-07 13:05:14,443] Trial 9 finished with value: 1.3143928608097688 and parameters: {'subsample': 0.9, 'n_estimators': 369, 'learning_rate': 0.04965507420680478}. Best is trial 9 with value: 1.3143928608097688.\n",
      "[I 2023-12-07 13:05:14,651] Trial 10 finished with value: 1.31633497330147 and parameters: {'subsample': 1, 'n_estimators': 333, 'learning_rate': 0.0496221754385571}. Best is trial 9 with value: 1.3143928608097688.\n",
      "[I 2023-12-07 13:05:14,835] Trial 11 finished with value: 1.314946986250999 and parameters: {'subsample': 0.85, 'n_estimators': 335, 'learning_rate': 0.04965164063898355}. Best is trial 9 with value: 1.3143928608097688.\n",
      "[I 2023-12-07 13:05:15,026] Trial 12 finished with value: 1.314862528831624 and parameters: {'subsample': 0.85, 'n_estimators': 348, 'learning_rate': 0.04992164301040924}. Best is trial 9 with value: 1.3143928608097688.\n",
      "[I 2023-12-07 13:05:15,307] Trial 13 finished with value: 1.3131939428337902 and parameters: {'subsample': 1, 'n_estimators': 354, 'learning_rate': 0.04717623969140866}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:15,533] Trial 14 finished with value: 1.3188486907286212 and parameters: {'subsample': 1, 'n_estimators': 358, 'learning_rate': 0.04693753782083861}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:15,657] Trial 15 finished with value: 1.3212698272018353 and parameters: {'subsample': 1, 'n_estimators': 202, 'learning_rate': 0.04442555953966956}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:15,860] Trial 16 finished with value: 1.31693167687987 and parameters: {'subsample': 0.95, 'n_estimators': 313, 'learning_rate': 0.047574134259348005}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:16,169] Trial 17 finished with value: 1.3194479296312274 and parameters: {'subsample': 0.8, 'n_estimators': 399, 'learning_rate': 0.0441341668617718}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:16,387] Trial 18 finished with value: 1.3148910499528255 and parameters: {'subsample': 1, 'n_estimators': 359, 'learning_rate': 0.0480309782450882}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:16,563] Trial 19 finished with value: 1.3213922333367558 and parameters: {'subsample': 1, 'n_estimators': 304, 'learning_rate': 0.047824468420471035}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:16,793] Trial 20 finished with value: 1.3168562499485537 and parameters: {'subsample': 0.95, 'n_estimators': 372, 'learning_rate': 0.0449365253074817}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:16,984] Trial 21 finished with value: 1.3157840613646692 and parameters: {'subsample': 0.85, 'n_estimators': 356, 'learning_rate': 0.04967113156558757}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:17,167] Trial 22 finished with value: 1.31769261708904 and parameters: {'subsample': 0.85, 'n_estimators': 340, 'learning_rate': 0.048109882450648934}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:17,362] Trial 23 finished with value: 1.3132856975979599 and parameters: {'subsample': 0.8, 'n_estimators': 348, 'learning_rate': 0.048482783257675174}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:17,584] Trial 24 finished with value: 1.3174433094481188 and parameters: {'subsample': 0.8, 'n_estimators': 388, 'learning_rate': 0.04841571080924707}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:17,819] Trial 25 finished with value: 1.3160195479959216 and parameters: {'subsample': 0.8, 'n_estimators': 368, 'learning_rate': 0.04633801410732674}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:18,024] Trial 26 finished with value: 1.3195249174554347 and parameters: {'subsample': 0.8, 'n_estimators': 321, 'learning_rate': 0.04784410856232283}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:18,232] Trial 27 finished with value: 1.3182604173071069 and parameters: {'subsample': 1, 'n_estimators': 341, 'learning_rate': 0.045933581196795546}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:18,501] Trial 28 finished with value: 1.3216288651720027 and parameters: {'subsample': 0.8, 'n_estimators': 399, 'learning_rate': 0.04878450468104316}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:18,669] Trial 29 finished with value: 1.3217223725464644 and parameters: {'subsample': 0.95, 'n_estimators': 302, 'learning_rate': 0.043219607357927924}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:18,885] Trial 30 finished with value: 1.317488921580149 and parameters: {'subsample': 0.9, 'n_estimators': 382, 'learning_rate': 0.04113244947150943}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:19,208] Trial 31 finished with value: 1.3166157989339755 and parameters: {'subsample': 0.85, 'n_estimators': 347, 'learning_rate': 0.049773568851477254}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:19,431] Trial 32 finished with value: 1.3210733263171672 and parameters: {'subsample': 0.9, 'n_estimators': 351, 'learning_rate': 0.049939322095089486}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:19,628] Trial 33 finished with value: 1.320365965816718 and parameters: {'subsample': 0.8, 'n_estimators': 365, 'learning_rate': 0.04873126329400919}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:19,820] Trial 34 finished with value: 1.3137624232927274 and parameters: {'subsample': 0.9, 'n_estimators': 324, 'learning_rate': 0.046624269150313286}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:20,005] Trial 35 finished with value: 1.322010305847058 and parameters: {'subsample': 0.9, 'n_estimators': 325, 'learning_rate': 0.047151287281033995}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:20,174] Trial 36 finished with value: 1.3195169711467436 and parameters: {'subsample': 0.9, 'n_estimators': 315, 'learning_rate': 0.04588849585970116}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:20,341] Trial 37 finished with value: 1.3190791503559813 and parameters: {'subsample': 0.9, 'n_estimators': 286, 'learning_rate': 0.04693134230660071}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:20,517] Trial 38 finished with value: 1.3185895219047377 and parameters: {'subsample': 0.9, 'n_estimators': 327, 'learning_rate': 0.04502435949422464}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:20,723] Trial 39 finished with value: 1.3178172131567853 and parameters: {'subsample': 0.9, 'n_estimators': 377, 'learning_rate': 0.04861289793548332}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:20,919] Trial 40 finished with value: 1.3175534969492082 and parameters: {'subsample': 1, 'n_estimators': 312, 'learning_rate': 0.046692434028221264}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:21,120] Trial 41 finished with value: 1.3176243705711255 and parameters: {'subsample': 0.85, 'n_estimators': 347, 'learning_rate': 0.04897208160273391}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:21,327] Trial 42 finished with value: 1.3157215087286476 and parameters: {'subsample': 0.85, 'n_estimators': 363, 'learning_rate': 0.04901264192393946}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:21,610] Trial 43 finished with value: 1.319908899402494 and parameters: {'subsample': 0.9, 'n_estimators': 336, 'learning_rate': 0.049978705867676686}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:21,880] Trial 44 finished with value: 1.3193383530990024 and parameters: {'subsample': 0.9, 'n_estimators': 347, 'learning_rate': 0.04737436103941502}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:22,105] Trial 45 finished with value: 1.3155591344446043 and parameters: {'subsample': 0.95, 'n_estimators': 384, 'learning_rate': 0.046316877648082365}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:22,272] Trial 46 finished with value: 1.3146343559916935 and parameters: {'subsample': 1, 'n_estimators': 270, 'learning_rate': 0.04892184389282806}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:22,415] Trial 47 finished with value: 1.3193317842773864 and parameters: {'subsample': 1, 'n_estimators': 234, 'learning_rate': 0.0475854145900759}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:22,558] Trial 48 finished with value: 1.3177636690251266 and parameters: {'subsample': 1, 'n_estimators': 245, 'learning_rate': 0.04888336739833442}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:22,719] Trial 49 finished with value: 1.3185484794381115 and parameters: {'subsample': 1, 'n_estimators': 270, 'learning_rate': 0.04530466778125072}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:22,882] Trial 50 finished with value: 1.315679499444318 and parameters: {'subsample': 1, 'n_estimators': 297, 'learning_rate': 0.04756449788773557}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:23,073] Trial 51 finished with value: 1.3153163328949342 and parameters: {'subsample': 0.85, 'n_estimators': 330, 'learning_rate': 0.049021559288039335}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:23,222] Trial 52 finished with value: 1.3186585581983712 and parameters: {'subsample': 1, 'n_estimators': 254, 'learning_rate': 0.04809425529778921}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:23,378] Trial 53 finished with value: 1.3222325070856829 and parameters: {'subsample': 0.8, 'n_estimators': 271, 'learning_rate': 0.046954572672751126}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:23,567] Trial 54 finished with value: 1.3176271789769372 and parameters: {'subsample': 1, 'n_estimators': 357, 'learning_rate': 0.04925059371898221}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:23,747] Trial 55 finished with value: 1.3133550245127712 and parameters: {'subsample': 0.85, 'n_estimators': 294, 'learning_rate': 0.04825846246410187}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:23,926] Trial 56 finished with value: 1.3186465913403542 and parameters: {'subsample': 0.9, 'n_estimators': 297, 'learning_rate': 0.048361192938778844}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:24,109] Trial 57 finished with value: 1.3168416251824582 and parameters: {'subsample': 0.8, 'n_estimators': 278, 'learning_rate': 0.04643743373017398}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:24,278] Trial 58 finished with value: 1.3169305586434663 and parameters: {'subsample': 0.85, 'n_estimators': 290, 'learning_rate': 0.04542137938937789}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:24,437] Trial 59 finished with value: 1.316919319671433 and parameters: {'subsample': 0.95, 'n_estimators': 262, 'learning_rate': 0.04776103782424088}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:24,628] Trial 60 finished with value: 1.3157315379800116 and parameters: {'subsample': 1, 'n_estimators': 309, 'learning_rate': 0.045841388815482664}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:24,807] Trial 61 finished with value: 1.3186066486777075 and parameters: {'subsample': 0.85, 'n_estimators': 319, 'learning_rate': 0.04946523149839505}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:25,033] Trial 62 finished with value: 1.3182969911155709 and parameters: {'subsample': 0.85, 'n_estimators': 373, 'learning_rate': 0.04837976273903966}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:25,223] Trial 63 finished with value: 1.3182342404972016 and parameters: {'subsample': 0.85, 'n_estimators': 340, 'learning_rate': 0.0493012406221896}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:25,417] Trial 64 finished with value: 1.3206243369715265 and parameters: {'subsample': 0.85, 'n_estimators': 351, 'learning_rate': 0.04994656924098387}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:25,642] Trial 65 finished with value: 1.3197314013493644 and parameters: {'subsample': 0.8, 'n_estimators': 334, 'learning_rate': 0.04814475258868602}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:25,844] Trial 66 finished with value: 1.3165118134971916 and parameters: {'subsample': 0.9, 'n_estimators': 368, 'learning_rate': 0.047205495103148545}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:25,994] Trial 67 finished with value: 1.3187542510740105 and parameters: {'subsample': 0.85, 'n_estimators': 229, 'learning_rate': 0.04935106961567996}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:26,194] Trial 68 finished with value: 1.3158320921199365 and parameters: {'subsample': 0.8, 'n_estimators': 353, 'learning_rate': 0.0484106254504074}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:26,516] Trial 69 finished with value: 1.3174147680711465 and parameters: {'subsample': 1, 'n_estimators': 392, 'learning_rate': 0.046573882635382854}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:26,716] Trial 70 finished with value: 1.318924992359119 and parameters: {'subsample': 0.9, 'n_estimators': 360, 'learning_rate': 0.04759983587120594}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:26,915] Trial 71 finished with value: 1.3208895623439822 and parameters: {'subsample': 1, 'n_estimators': 344, 'learning_rate': 0.04815439856122291}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:27,201] Trial 72 finished with value: 1.3175052931312445 and parameters: {'subsample': 1, 'n_estimators': 368, 'learning_rate': 0.04945860676996047}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:27,451] Trial 73 finished with value: 1.3154617027502862 and parameters: {'subsample': 1, 'n_estimators': 360, 'learning_rate': 0.04854810089690611}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:27,663] Trial 74 finished with value: 1.3211443864925034 and parameters: {'subsample': 1, 'n_estimators': 292, 'learning_rate': 0.04702658964657639}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:27,827] Trial 75 finished with value: 1.3197073338197542 and parameters: {'subsample': 0.95, 'n_estimators': 280, 'learning_rate': 0.04777816071209796}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:28,009] Trial 76 finished with value: 1.3149014196580282 and parameters: {'subsample': 0.9, 'n_estimators': 306, 'learning_rate': 0.048917293734224127}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:28,227] Trial 77 finished with value: 1.3215942773547618 and parameters: {'subsample': 0.85, 'n_estimators': 376, 'learning_rate': 0.04610518378961426}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:28,412] Trial 78 finished with value: 1.31729047167687 and parameters: {'subsample': 1, 'n_estimators': 319, 'learning_rate': 0.04465642842597263}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:28,589] Trial 79 finished with value: 1.314407671236522 and parameters: {'subsample': 0.8, 'n_estimators': 329, 'learning_rate': 0.04998440722887494}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:28,778] Trial 80 finished with value: 1.3165430167655827 and parameters: {'subsample': 0.8, 'n_estimators': 337, 'learning_rate': 0.04989160557138379}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:28,974] Trial 81 finished with value: 1.3160755478673016 and parameters: {'subsample': 0.8, 'n_estimators': 329, 'learning_rate': 0.04946049608109417}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:29,181] Trial 82 finished with value: 1.3167911810399011 and parameters: {'subsample': 0.8, 'n_estimators': 354, 'learning_rate': 0.04881393807488891}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:29,382] Trial 83 finished with value: 1.3150711718668642 and parameters: {'subsample': 0.8, 'n_estimators': 344, 'learning_rate': 0.048051566060540944}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:29,567] Trial 84 finished with value: 1.316565245061766 and parameters: {'subsample': 0.9, 'n_estimators': 325, 'learning_rate': 0.04997707711111976}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:29,849] Trial 85 finished with value: 1.3158517441858941 and parameters: {'subsample': 0.8, 'n_estimators': 348, 'learning_rate': 0.047333262135274314}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:30,071] Trial 86 finished with value: 1.3181221397785756 and parameters: {'subsample': 1, 'n_estimators': 363, 'learning_rate': 0.048717223676909324}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:30,301] Trial 87 finished with value: 1.3179015533650589 and parameters: {'subsample': 0.85, 'n_estimators': 380, 'learning_rate': 0.04915075729945296}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:30,487] Trial 88 finished with value: 1.3204750173324171 and parameters: {'subsample': 0.9, 'n_estimators': 340, 'learning_rate': 0.04664328719198305}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:30,720] Trial 89 finished with value: 1.316960959780893 and parameters: {'subsample': 1, 'n_estimators': 370, 'learning_rate': 0.047822219202556665}. Best is trial 13 with value: 1.3131939428337902.\n",
      "[I 2023-12-07 13:05:30,907] Trial 90 finished with value: 1.310936317318466 and parameters: {'subsample': 0.95, 'n_estimators': 332, 'learning_rate': 0.04945272800526261}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:31,083] Trial 91 finished with value: 1.3183774304711042 and parameters: {'subsample': 0.95, 'n_estimators': 314, 'learning_rate': 0.04952237362675037}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:31,281] Trial 92 finished with value: 1.3216339908902215 and parameters: {'subsample': 0.95, 'n_estimators': 333, 'learning_rate': 0.04833915678452062}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:31,487] Trial 93 finished with value: 1.316832498219694 and parameters: {'subsample': 0.95, 'n_estimators': 357, 'learning_rate': 0.04865788480407823}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:31,668] Trial 94 finished with value: 1.3140732928976988 and parameters: {'subsample': 0.95, 'n_estimators': 320, 'learning_rate': 0.04911382108459821}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:31,867] Trial 95 finished with value: 1.320583231095394 and parameters: {'subsample': 0.95, 'n_estimators': 323, 'learning_rate': 0.04924718802601319}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:32,060] Trial 96 finished with value: 1.3160009720021715 and parameters: {'subsample': 0.95, 'n_estimators': 330, 'learning_rate': 0.04963378885141936}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:32,232] Trial 97 finished with value: 1.317876887703592 and parameters: {'subsample': 0.95, 'n_estimators': 317, 'learning_rate': 0.04914848851300484}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:32,405] Trial 98 finished with value: 1.3162498272753476 and parameters: {'subsample': 0.95, 'n_estimators': 309, 'learning_rate': 0.04999016112433914}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:32,639] Trial 99 finished with value: 1.3149037720819463 and parameters: {'subsample': 0.95, 'n_estimators': 302, 'learning_rate': 0.047291283222702145}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:32,818] Trial 100 finished with value: 1.320524077675894 and parameters: {'subsample': 0.85, 'n_estimators': 214, 'learning_rate': 0.04871023861165585}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:33,024] Trial 101 finished with value: 1.3186282345360414 and parameters: {'subsample': 0.8, 'n_estimators': 342, 'learning_rate': 0.04819116253164329}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:33,367] Trial 102 finished with value: 1.318340963251416 and parameters: {'subsample': 0.9, 'n_estimators': 335, 'learning_rate': 0.04788112577726945}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:33,577] Trial 103 finished with value: 1.3168697002189342 and parameters: {'subsample': 1, 'n_estimators': 351, 'learning_rate': 0.048907400616895226}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:33,761] Trial 104 finished with value: 1.3179964276477316 and parameters: {'subsample': 0.85, 'n_estimators': 276, 'learning_rate': 0.04968858118334109}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:33,923] Trial 105 finished with value: 1.3160867631204336 and parameters: {'subsample': 0.9, 'n_estimators': 285, 'learning_rate': 0.04748224295435666}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:34,114] Trial 106 finished with value: 1.3188299450355507 and parameters: {'subsample': 1, 'n_estimators': 327, 'learning_rate': 0.04849311583322909}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:34,310] Trial 107 finished with value: 1.320635718509067 and parameters: {'subsample': 0.8, 'n_estimators': 321, 'learning_rate': 0.049177383351638855}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:34,475] Trial 108 finished with value: 1.3192426526471441 and parameters: {'subsample': 0.95, 'n_estimators': 261, 'learning_rate': 0.04688827971712601}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:34,674] Trial 109 finished with value: 1.3138832912164295 and parameters: {'subsample': 0.85, 'n_estimators': 348, 'learning_rate': 0.04952963961251786}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:34,861] Trial 110 finished with value: 1.3131888307262725 and parameters: {'subsample': 0.85, 'n_estimators': 350, 'learning_rate': 0.04956926176666885}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:35,045] Trial 111 finished with value: 1.3137684927884274 and parameters: {'subsample': 0.85, 'n_estimators': 346, 'learning_rate': 0.0495689759948714}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:35,242] Trial 112 finished with value: 1.317992534767475 and parameters: {'subsample': 0.85, 'n_estimators': 348, 'learning_rate': 0.049581133991941986}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:35,431] Trial 113 finished with value: 1.3187307460933861 and parameters: {'subsample': 0.85, 'n_estimators': 338, 'learning_rate': 0.049206880454214036}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:35,718] Trial 114 finished with value: 1.318896979309702 and parameters: {'subsample': 0.85, 'n_estimators': 331, 'learning_rate': 0.04847236353361806}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:35,909] Trial 115 finished with value: 1.3157689538272186 and parameters: {'subsample': 0.85, 'n_estimators': 345, 'learning_rate': 0.04951116923958955}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:36,098] Trial 116 finished with value: 1.316610592838745 and parameters: {'subsample': 0.85, 'n_estimators': 353, 'learning_rate': 0.04890597380333186}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:36,292] Trial 117 finished with value: 1.3169520287568046 and parameters: {'subsample': 0.85, 'n_estimators': 338, 'learning_rate': 0.04818343278349454}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:36,504] Trial 118 finished with value: 1.3179483882865024 and parameters: {'subsample': 0.85, 'n_estimators': 359, 'learning_rate': 0.04992796602488355}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:36,703] Trial 119 finished with value: 1.317939241380132 and parameters: {'subsample': 0.85, 'n_estimators': 363, 'learning_rate': 0.04791611873228448}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:36,928] Trial 120 finished with value: 1.3183561445729561 and parameters: {'subsample': 0.9, 'n_estimators': 349, 'learning_rate': 0.04900793909886661}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:37,127] Trial 121 finished with value: 1.3155094138623749 and parameters: {'subsample': 0.85, 'n_estimators': 342, 'learning_rate': 0.04949977640950768}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:37,303] Trial 122 finished with value: 1.3185049755017728 and parameters: {'subsample': 0.85, 'n_estimators': 297, 'learning_rate': 0.04995818501864239}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:37,458] Trial 123 finished with value: 1.317966706279301 and parameters: {'subsample': 0.85, 'n_estimators': 251, 'learning_rate': 0.04853716011339182}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:37,663] Trial 124 finished with value: 1.316433532646613 and parameters: {'subsample': 0.85, 'n_estimators': 365, 'learning_rate': 0.0492489040577175}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:37,863] Trial 125 finished with value: 1.3177330291854885 and parameters: {'subsample': 0.8, 'n_estimators': 354, 'learning_rate': 0.04962627538670221}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:38,069] Trial 126 finished with value: 1.3196577544266535 and parameters: {'subsample': 0.85, 'n_estimators': 326, 'learning_rate': 0.04878483902092395}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:38,364] Trial 127 finished with value: 1.3147306653127628 and parameters: {'subsample': 0.9, 'n_estimators': 333, 'learning_rate': 0.047656328084734675}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:38,602] Trial 128 finished with value: 1.3188636614883713 and parameters: {'subsample': 0.9, 'n_estimators': 334, 'learning_rate': 0.04737755429075573}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:38,783] Trial 129 finished with value: 1.317482343794476 and parameters: {'subsample': 0.9, 'n_estimators': 310, 'learning_rate': 0.04763322639741987}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:38,972] Trial 130 finished with value: 1.3192182568640807 and parameters: {'subsample': 0.9, 'n_estimators': 323, 'learning_rate': 0.04814841553277698}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:39,162] Trial 131 finished with value: 1.3185131053800647 and parameters: {'subsample': 0.9, 'n_estimators': 344, 'learning_rate': 0.04906243203500392}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:39,354] Trial 132 finished with value: 1.3162703561630436 and parameters: {'subsample': 0.95, 'n_estimators': 331, 'learning_rate': 0.0485544582758725}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:39,549] Trial 133 finished with value: 1.315670011291918 and parameters: {'subsample': 0.8, 'n_estimators': 339, 'learning_rate': 0.04997737283058106}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:39,897] Trial 134 finished with value: 1.317902423652713 and parameters: {'subsample': 0.9, 'n_estimators': 315, 'learning_rate': 0.049337122389444606}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:40,178] Trial 135 finished with value: 1.3167660442315325 and parameters: {'subsample': 0.85, 'n_estimators': 349, 'learning_rate': 0.04689048487898721}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:40,391] Trial 136 finished with value: 1.3185200430162207 and parameters: {'subsample': 0.95, 'n_estimators': 355, 'learning_rate': 0.04639361996169267}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:40,686] Trial 137 finished with value: 1.3165592494254161 and parameters: {'subsample': 0.8, 'n_estimators': 335, 'learning_rate': 0.04801407691664368}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:40,871] Trial 138 finished with value: 1.3158261778721079 and parameters: {'subsample': 0.9, 'n_estimators': 343, 'learning_rate': 0.0495612636664608}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:41,047] Trial 139 finished with value: 1.317124515565829 and parameters: {'subsample': 0.85, 'n_estimators': 305, 'learning_rate': 0.0488382361875688}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:41,264] Trial 140 finished with value: 1.3190258702377762 and parameters: {'subsample': 0.85, 'n_estimators': 327, 'learning_rate': 0.04835056943487879}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:41,471] Trial 141 finished with value: 1.31711385089573 and parameters: {'subsample': 1, 'n_estimators': 359, 'learning_rate': 0.04771435048483088}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:41,688] Trial 142 finished with value: 1.322942629079495 and parameters: {'subsample': 1, 'n_estimators': 365, 'learning_rate': 0.04708461343581067}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:41,900] Trial 143 finished with value: 1.3175338197412676 and parameters: {'subsample': 1, 'n_estimators': 346, 'learning_rate': 0.04927772001820455}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:42,131] Trial 144 finished with value: 1.3170530264647122 and parameters: {'subsample': 1, 'n_estimators': 374, 'learning_rate': 0.04873353836492123}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:42,301] Trial 145 finished with value: 1.320330166459324 and parameters: {'subsample': 1, 'n_estimators': 267, 'learning_rate': 0.049599572546294726}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:42,500] Trial 146 finished with value: 1.3204961925700607 and parameters: {'subsample': 0.95, 'n_estimators': 351, 'learning_rate': 0.04824127677510989}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:42,700] Trial 147 finished with value: 1.3162222190777815 and parameters: {'subsample': 0.8, 'n_estimators': 357, 'learning_rate': 0.049046448510209416}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:42,944] Trial 148 finished with value: 1.3209213535264501 and parameters: {'subsample': 0.9, 'n_estimators': 370, 'learning_rate': 0.047500246372206796}. Best is trial 90 with value: 1.310936317318466.\n",
      "[I 2023-12-07 13:05:43,160] Trial 149 finished with value: 1.3191703415972134 and parameters: {'subsample': 0.85, 'n_estimators': 339, 'learning_rate': 0.04788456190115461}. Best is trial 90 with value: 1.310936317318466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.95, 'n_estimators': 332, 'learning_rate': 0.04945272800526261}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000206 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 447\n",
      "[LightGBM] [Info] Number of data points in the train set: 7784, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 3.371274\n",
      "농업경영체별 평가지표 결과\n",
      "MAE: 1.24\n",
      "MSE: 2.98\n",
      "RMSE: 1.73\n",
      "RMSPE: 128.12%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "배정신청인원 10명 이상 시군구 단위 평가지표\n",
      "MAE: 7.93\n",
      "MSE: 131.69\n",
      "RMSE: 11.48\n",
      "RMSPE: 20.61%\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params={\n",
    "        'n_jobs':-1,\n",
    "        'objective':'regression',\n",
    "        'verbosity':0,\n",
    "        'subsample': trial.suggest_categorical('subsample',[0.8,0.85,0.90,0.95,1]),\n",
    "        'n_estimators': trial.suggest_int('n_estimators',200,400),\n",
    "        'learning_rate': trial.suggest_float('learning_rate',0.03,0.05)\n",
    "    }\n",
    "    # 학습 모델 생성\n",
    "    model_reg= LGBMRegressor(**params)\n",
    "    \n",
    "    #트레인 셋 학습\n",
    "    model_reg.fit(X_train,Y_train)\n",
    "    \n",
    "    #검증 데이터 셋으로 모델 검증\n",
    "    score = mean_absolute_error(model_reg.predict(X_valid), Y_valid)\n",
    "    return score\n",
    "\n",
    "study=optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=150)\n",
    "\n",
    "# 최적화된 파라미터 값 확인\n",
    "best_params = study.best_params\n",
    "print(best_params)\n",
    "\n",
    "model_reg =  LGBMRegressor(**best_params)\n",
    "model_reg.fit(X_train,Y_train)\n",
    "\n",
    "#예측값 \n",
    "pred=model_reg.predict(X_test)\n",
    "# 인원 수 예측이기에 예측된 결과에 반올림 적용\n",
    "pred=pd.DataFrame(pred,columns=['예측값'])\n",
    "#반올림\n",
    "pred['예측값']=round(pred['예측값'],0)\n",
    "#평가지표\n",
    "print('농업경영체별 평가지표 결과')\n",
    "Evaluation_metric(Y_test,pred=pred['예측값'])\n",
    "print('-'*100)\n",
    "\n",
    "test_index=X_test.index.tolist()\n",
    "data_test=data_real.loc[test_index]\n",
    "data_test=data_test.reset_index()\n",
    "data_test.drop(columns=['index'],inplace=True)\n",
    "#예측값\n",
    "data_test['predict']=pred\n",
    "result=data_test.groupby(['지자체명_시도','지자체명_시군구'])[['합계','predict']].sum().reset_index()\n",
    "result_1=result.query('합계>10')\n",
    "print('배정신청인원 10명 이상 시군구 단위 평가지표')\n",
    "Evaluation_metric(result_1['합계'],pred=result_1['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56fdf45-04d3-46f7-9eee-9704ff243932",
   "metadata": {},
   "source": [
    "## 7. 결과 활용 및 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb54fd-6a9c-4309-91c8-96be189f52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "조치사항=[]\n",
    "for i in result_1.index:\n",
    "    if abs(result_1.loc[i,'오차']) <= 0.1:\n",
    "        조치사항.append('현행유지')\n",
    "    elif result_1.loc[i,'오차']>0.1:\n",
    "        조치사항.append('배정감축')\n",
    "    elif result_1.loc[i,'오차']<-0.1:\n",
    "        조치사항.append('추가배정')\n",
    "\n",
    "        \n",
    "result_1['조치사항']=조치사항\n",
    "result_1.to_csv('최종예측 결과_LightGBM.csv',encoding='EUC-KR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
