{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b539361f-436f-4ae4-b158-8abc4e5686dc",
   "metadata": {},
   "source": [
    "# 0. 기본 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3276be07-38de-481d-87d7-ebc29c5fcc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "sns.set(font=\"Malgun Gothic\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a40617-bfef-45c4-9290-bb0c430a9296",
   "metadata": {},
   "source": [
    "# 데이터 분할 및 평가 지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d933b20-d2b6-4439-a120-c89e0537cace",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8d648-088d-4fdb-91ad-47eb4ec4f855",
   "metadata": {},
   "source": [
    "# LightGBM 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb352d1c-cf1e-4d10-805f-4108f3585859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca6d5a3-bbc3-4a03-b75a-6461d478a256",
   "metadata": {},
   "source": [
    "# 파라미터 튜닝 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6115cec6-b863-4ff6-8f2c-7bb6ad24f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110a435-664d-41ab-bcb4-1996e10255bc",
   "metadata": {},
   "source": [
    "# 빈도테이블 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8d3f27f-7759-46b8-8f8a-1db72e326e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(x):\n",
    "    data1=pd.DataFrame(x.value_counts()).reset_index()\n",
    "    data1.columns=['category','빈도수']\n",
    "    return data1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c32f641-a14f-41eb-be54-1d1e4e4fb3c2",
   "metadata": {},
   "source": [
    "# Barplot 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "123239c1-5fd8-4a9f-a363-8a8668a48dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bargraph(x,y,x_label,y_label,figsize1,figsize2,data):\n",
    "    plt.figure(figsize=(figsize1, figsize2))\n",
    "    if data[x].dtypes=='int64':\n",
    "        data[x]=data[x].astype('str')\n",
    "    data=data.sort_values(by=y,ascending=False).reset_index()\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        g=sns.barplot(x,y,data=data)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        g.text(index,row[y],row[y],color='black',ha='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd9a2f-591e-4a68-989f-0eb09a0025c9",
   "metadata": {},
   "source": [
    "# 성능 지표 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a4b9862-177b-44b2-82ce-53e80fb0b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능지표 추출\n",
    "def Evaluation_metric(actual,pred):\n",
    "    print(f'MAE: {round(mean_absolute_error(actual,pred),2)}')\n",
    "    print(f'MSE: {round(mean_squared_error(actual,pred),2)}')\n",
    "    print(f'RMSE: {round(sqrt(mean_squared_error(actual,pred)),2)}')\n",
    "    #print(f'RMSPE: {round(sqrt(mean_squared_error(actual,pred))/np.mean(actual)*100,2)}%')\n",
    "    print(f'RMSPE: {round(np.sqrt(np.mean(((actual - pred) / actual) ** 2)) * 100, 2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ec385c-57b3-483a-8534-0d55e7050742",
   "metadata": {},
   "source": [
    "# 1. 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19804a4e-d47e-4739-9f18-7f2195ab2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(42) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad09e1-f89b-43de-a320-bfff6d9a8adb",
   "metadata": {},
   "source": [
    "# 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40d15d0e-3227-43eb-a9c8-cde7ef9e0611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Valid, Test Split용 데이터\n",
    "data=pd.read_csv(os.listdir()[10],encoding='EUC-KR')\n",
    "# 지표 확인용 데이터\n",
    "data_real=pd.read_csv(os.listdir()[10],encoding='EUC-KR')\n",
    "# 배정신청인원 0명 제거\n",
    "data=data.query('합계!=0')\n",
    "#필요 컬럼 추출\n",
    "selected_columns_1=['구분','합계', '작물 종류','농지면적(실제경작)','전년대비농경체증감률','고령농경체비율','전년도이탈인원','전년도활용여부']\n",
    "selected_columns_2=['비고', '지자체명_시도', '지자체명_시군구', '구분', '농업경영체','합계', '작물 종류','농지면적(실제경작)','전년대비농경체증감률','고령농경체비율','전년도이탈인원','전년도활용여부'] #원본 데이터 컬럼\n",
    "data=data[selected_columns_1]\n",
    "data_real=data_real[selected_columns_2]\n",
    "# 농지면적(실제경작) 컬럼명 변경\n",
    "data.rename(columns={'농지면적(실제경작)':'농지면적','작물 종류':'작물종류'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bde231-7e96-4ced-9a73-4f006325c7af",
   "metadata": {},
   "source": [
    "# 3. 이상치 제거: 농지 면적, 합계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28d83050-408c-4ec1-8a7a-b7d50a58c94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.query('0.04<농지면적<2.5')\n",
    "data=data.query('합계<11')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89e7a6-dcc3-4092-8994-e0c9323c9f4c",
   "metadata": {},
   "source": [
    "# 4. 데이터 분할 Train, Valid, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89b263f7-bd65-444b-a98f-264bb9ffa7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작물 종류 기준 층화 추출 Train Test 비율 8:2\n",
    "X=data.drop(columns=['합계']) #독립변수 Set\n",
    "Y=data['합계'] #Target 변수 set\n",
    "\n",
    "# Train, Test 분할\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.2,stratify=X['작물종류'],random_state=42)\n",
    "\n",
    "# 2차 Train, Validation 분할\n",
    "X_train, X_valid, Y_train, Y_valid=train_test_split(X_train,Y_train,test_size=0.2,stratify=X_train['작물종류'],random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a35d3e-5491-4b92-8d1c-cb039e03daf9",
   "metadata": {},
   "source": [
    "# 5. 연속형 변수 정규화 & 범주형 변수 라벨 인코딩 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "100e66d4-1b3b-452f-b4f5-641f48b64623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속형 변수 정규화\n",
    "min_max_scaler=MinMaxScaler()\n",
    "for i in X_train.columns:\n",
    "    if (X_train[i].dtypes!='object'):\n",
    "        X_train[i]=min_max_scaler.fit_transform(X_train[[i]])\n",
    "        X_valid[i]=min_max_scaler.transform(X_valid[[i]])\n",
    "        X_test[i]=min_max_scaler.transform(X_test[[i]])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7c1dbe6-0673-4efe-907f-183411eb2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 변수 라벨 인코딩\n",
    "label_encoder=LabelEncoder()\n",
    "for i in X_train.columns:\n",
    "    if X_train[i].dtypes=='object':\n",
    "        X_train[i]=label_encoder.fit_transform(X_train[i])\n",
    "        X_valid[i]=label_encoder.transform(X_valid[i])\n",
    "        X_test[i]=label_encoder.transform(X_test[i])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd5876-ac45-4e04-8274-7910ad789e75",
   "metadata": {},
   "source": [
    "# 6. LightGBM parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee1d72-3cd5-4a48-ab28-bb7f2f0789bf",
   "metadata": {},
   "source": [
    "- 주요 파라미터 설명\n",
    "\n",
    "- num_leaves: 트리가 가질 수 있는 최대 잎의 수\n",
    "\n",
    "- max_depth: 최대 트리 깊이\n",
    "\n",
    "- learning_rate: 학습률\n",
    "\n",
    "- n_estimator: 생성할 부스팅 트리 개수\n",
    "\n",
    "- subsample: 훈련데이터 샘플링 비율\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "- 초기 파라미터\n",
    "- model_reg=LGBMRegressor(n_jobs=-1,n_estimators=150,learning_rate=0.05,random_state=42,objective='regression')\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8cdd0e-289c-4ae4-b8e0-791d0322c694",
   "metadata": {},
   "source": [
    "# 7. 초기 기본 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e00e6b92-3426-4aad-8dd5-64e4c5bfeb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000245 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 447\n",
      "[LightGBM] [Info] Number of data points in the train set: 7784, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 3.371274\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE: 1.25\n",
      "MSE: 2.97\n",
      "RMSE: 1.72\n",
      "RMSPE: 125.02%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "MAE: 8.2\n",
      "MSE: 140.0\n",
      "RMSE: 11.83\n",
      "RMSPE: 21.14%\n"
     ]
    }
   ],
   "source": [
    "model_reg=LGBMRegressor(n_jobs=-1,n_estimators=200,learning_rate=0.05,random_state=42,objective='regression')\n",
    "model_reg.fit(X_train,Y_train)\n",
    "pred=model_reg.predict(X_test)\n",
    "# 인원 수 예측이기에 예측된 결과에 반올림 적용\n",
    "pred=pd.DataFrame(pred,columns=['예측값'])\n",
    "pred['예측값']=round(pred['예측값'],0)\n",
    "pred\n",
    "print('-'*100)\n",
    "Evaluation_metric(Y_test,pred=pred['예측값'])\n",
    "print('-'*100)\n",
    "# Test data Set\n",
    "test_index=X_test.index.tolist()\n",
    "data_test=data_real.loc[test_index]\n",
    "data_test=data_test.reset_index()\n",
    "data_test.drop(columns=['index'],inplace=True)\n",
    "data_test['predict']=pred\n",
    "result=data_test.groupby(['지자체명_시도','지자체명_시군구'])[['합계','predict']].sum().reset_index()\n",
    "result_1=result.query('합계>10')\n",
    "Evaluation_metric(result_1['합계'],pred=result_1['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379002d5-a73e-41d6-b1b5-9e0c660747a3",
   "metadata": {},
   "source": [
    "# 8. Bayesian Optimization 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "730a8b9d-ef6b-4884-b395-12e08ffcb873",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | n_esti... | subsample |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m3.594    \u001b[0m | \u001b[0m0.05741  \u001b[0m | \u001b[0m227.0    \u001b[0m | \u001b[0m0.847    \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m3.527    \u001b[0m | \u001b[0m0.03855  \u001b[0m | \u001b[0m244.7    \u001b[0m | \u001b[0m0.8274   \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m3.637    \u001b[0m | \u001b[95m0.05541  \u001b[0m | \u001b[95m288.1    \u001b[0m | \u001b[95m0.9865   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m3.521    \u001b[0m | \u001b[0m0.04048  \u001b[0m | \u001b[0m235.3    \u001b[0m | \u001b[0m0.871    \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m3.539    \u001b[0m | \u001b[0m0.04219  \u001b[0m | \u001b[0m228.9    \u001b[0m | \u001b[0m0.8933   \u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m3.493    \u001b[0m | \u001b[0m0.03225  \u001b[0m | \u001b[0m230.6    \u001b[0m | \u001b[0m0.9037   \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m3.615    \u001b[0m | \u001b[0m0.05548  \u001b[0m | \u001b[0m252.2    \u001b[0m | \u001b[0m0.8799   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m3.493    \u001b[0m | \u001b[0m0.03163  \u001b[0m | \u001b[0m237.0    \u001b[0m | \u001b[0m0.9612   \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m3.606    \u001b[0m | \u001b[0m0.0546   \u001b[0m | \u001b[0m238.1    \u001b[0m | \u001b[0m0.8723   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m3.547    \u001b[0m | \u001b[0m0.04603  \u001b[0m | \u001b[0m204.4    \u001b[0m | \u001b[0m0.9528   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m3.544    \u001b[0m | \u001b[0m0.04225  \u001b[0m | \u001b[0m254.6    \u001b[0m | \u001b[0m0.9553   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m3.629    \u001b[0m | \u001b[0m0.05769  \u001b[0m | \u001b[0m238.2    \u001b[0m | \u001b[0m0.9733   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m3.605    \u001b[0m | \u001b[0m0.0587   \u001b[0m | \u001b[0m238.6    \u001b[0m | \u001b[0m0.9822   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m3.496    \u001b[0m | \u001b[0m0.03023  \u001b[0m | \u001b[0m288.5    \u001b[0m | \u001b[0m0.8525   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m3.626    \u001b[0m | \u001b[0m0.05647  \u001b[0m | \u001b[0m247.3    \u001b[0m | \u001b[0m0.9684   \u001b[0m |\n",
      "| \u001b[95m16       \u001b[0m | \u001b[95m3.657    \u001b[0m | \u001b[95m0.05745  \u001b[0m | \u001b[95m287.8    \u001b[0m | \u001b[95m0.978    \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m3.532    \u001b[0m | \u001b[0m0.03303  \u001b[0m | \u001b[0m287.6    \u001b[0m | \u001b[0m0.8122   \u001b[0m |\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m3.585    \u001b[0m | \u001b[0m0.04154  \u001b[0m | \u001b[0m287.9    \u001b[0m | \u001b[0m0.8156   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m3.572    \u001b[0m | \u001b[0m0.04403  \u001b[0m | \u001b[0m267.8    \u001b[0m | \u001b[0m0.8454   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m3.582    \u001b[0m | \u001b[0m0.04615  \u001b[0m | \u001b[0m252.2    \u001b[0m | \u001b[0m0.8692   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m3.597    \u001b[0m | \u001b[0m0.05695  \u001b[0m | \u001b[0m238.2    \u001b[0m | \u001b[0m0.9763   \u001b[0m |\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m3.592    \u001b[0m | \u001b[0m0.04889  \u001b[0m | \u001b[0m288.1    \u001b[0m | \u001b[0m0.9891   \u001b[0m |\n",
      "| \u001b[95m23       \u001b[0m | \u001b[95m3.657    \u001b[0m | \u001b[95m0.0566   \u001b[0m | \u001b[95m287.8    \u001b[0m | \u001b[95m0.9738   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m3.627    \u001b[0m | \u001b[0m0.05917  \u001b[0m | \u001b[0m248.5    \u001b[0m | \u001b[0m0.8245   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m3.616    \u001b[0m | \u001b[0m0.04911  \u001b[0m | \u001b[0m269.8    \u001b[0m | \u001b[0m0.8506   \u001b[0m |\n",
      "=============================================================\n",
      "최종 파라미터는 {'subsample': 0.903727415651983, 'n_estimators': 231, 'learning_rate': 0.032253191544211295}입니다\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000225 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 447\n",
      "[LightGBM] [Info] Number of data points in the train set: 7784, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 3.371274\n",
      "농업경영체별 평가지표 결과\n",
      "MAE: 1.26\n",
      "MSE: 2.97\n",
      "RMSE: 1.72\n",
      "RMSPE: 125.04%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "배정신청인원 10명 이상 시군구 단위 평가지표\n",
      "MAE: 8.54\n",
      "MSE: 158.43\n",
      "RMSE: 12.59\n",
      "RMSPE: 21.96%\n"
     ]
    }
   ],
   "source": [
    "# 목적 함수 정의\n",
    "results = {\n",
    "    'subsample': [],\n",
    "    'n_estimators': [],\n",
    "    'learning_rate': [],\n",
    "    'target': []  # 최적화 결과인 target 값 저장\n",
    "}\n",
    "\n",
    "def xgb_cv(subsample, n_estimators, learning_rate):\n",
    "    params = {\n",
    "        'subsample': subsample,\n",
    "        'n_estimators': int(n_estimators),\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_jobs':-1,\n",
    "        'objective':'regression',\n",
    "        'verbosity':0\n",
    "    }\n",
    "    \n",
    "    # XGBoost Regressor 모델 초기화\n",
    "    model_reg = LGBMRegressor(**params)\n",
    "    \n",
    "    #model Train 학습\n",
    "    model_reg.fit(X_train,Y_train)\n",
    "    #model validation\n",
    "    scores = -cross_val_score(model_reg, X_valid, Y_valid, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "    results['subsample'].append(subsample)\n",
    "    results['n_estimators'].append(n_estimators)\n",
    "    results['learning_rate'].append(learning_rate)\n",
    "    results['target'].append(scores)\n",
    "    return scores\n",
    "\n",
    "# Bayesian Optimization 수행\n",
    "xgbBO = BayesianOptimization(\n",
    "    xgb_cv,\n",
    "    {'subsample': (0.80, 1.0),\n",
    "     'n_estimators': (200, 300),\n",
    "     'learning_rate': (0.03,0.06)}\n",
    ")\n",
    "\n",
    "# 최적화\n",
    "xgbBO.maximize(init_points=10, n_iter=15)\n",
    "\n",
    "idx_of_min=results['target'].index(min(results['target']))\n",
    "min_pam={}\n",
    "for key,value in results.items():\n",
    "    if key=='target':\n",
    "        pass\n",
    "    else:\n",
    "        if (key=='max_depth') or (key=='n_estimators'):\n",
    "            min_pam[key]=int(round(value[idx_of_min],0))\n",
    "        else:\n",
    "            min_pam[key]=value[idx_of_min]\n",
    "            \n",
    "print(f'최종 파라미터는 {min_pam}입니다')\n",
    "\n",
    "model_reg = LGBMRegressor(**min_pam)\n",
    "model_reg.fit(X_train,Y_train)\n",
    "\n",
    "#예측값 \n",
    "pred=model_reg.predict(X_test)\n",
    "# 인원 수 예측이기에 예측된 결과에 반올림 적용\n",
    "pred=pd.DataFrame(pred,columns=['예측값'])\n",
    "#반올림\n",
    "pred['예측값']=round(pred['예측값'],0)\n",
    "#평가지표\n",
    "print('농업경영체별 평가지표 결과')\n",
    "Evaluation_metric(Y_test,pred=pred['예측값'])\n",
    "print('-'*100)\n",
    "\n",
    "test_index=X_test.index.tolist()\n",
    "data_test=data_real.loc[test_index]\n",
    "data_test=data_test.reset_index()\n",
    "data_test.drop(columns=['index'],inplace=True)\n",
    "#예측값\n",
    "data_test['predict']=pred\n",
    "result=data_test.groupby(['지자체명_시도','지자체명_시군구'])[['합계','predict']].sum().reset_index()\n",
    "result_1=result.query('합계>10')\n",
    "print('배정신청인원 10명 이상 시군구 단위 평가지표')\n",
    "Evaluation_metric(result_1['합계'],pred=result_1['predict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e38274-f942-4ef5-82ea-7c02660f4b91",
   "metadata": {},
   "source": [
    "# 9. OPTUNA 라이브러리 활용 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085b7136-45c8-490b-bd80-fc252c9171ed",
   "metadata": {},
   "source": [
    "파라미터 튜닝 코드\n",
    "\n",
    "- optuna.trial.Trial.suggest_categorical() : 리스트 범위 내에서 값을 선택한다.\n",
    "- optuna.trial.Trial.suggest_int() : 범위 내에서 정수형 값을 선택한다.\n",
    "- optuna.trial.Trial.suggest_float() : 범위 내에서 소수형 값을 선택한다.\n",
    "- optuna.trial.Trial.suggest_uniform() : 범위 내에서 균일분포 값을 선택한다.\n",
    "- optuna.trial.Trial.suggest_discrete_uniform() : 범위 내에서 이산 균일분포 값을 선택한다.\n",
    "- optuna.trial.Trial.suggest_loguniform() : 범위 내에서 로그 함수 값을 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eba89e45-f2df-4196-82b7-918be366fcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-28 11:11:16,190] A new study created in memory with name: no-name-14ea8d2a-daf8-485c-ae7e-876f70784d21\n",
      "[I 2023-11-28 11:11:16,406] Trial 0 finished with value: 1.322859975546507 and parameters: {'subsample': 0.8, 'n_estimators': 277, 'learning_rate': 0.03495557000618027}. Best is trial 0 with value: 1.322859975546507.\n",
      "[I 2023-11-28 11:11:16,576] Trial 1 finished with value: 1.3228084238145807 and parameters: {'subsample': 0.95, 'n_estimators': 354, 'learning_rate': 0.031732134014734854}. Best is trial 1 with value: 1.3228084238145807.\n",
      "[I 2023-11-28 11:11:16,740] Trial 2 finished with value: 1.3220283961506396 and parameters: {'subsample': 0.95, 'n_estimators': 356, 'learning_rate': 0.044453065545376806}. Best is trial 2 with value: 1.3220283961506396.\n",
      "[I 2023-11-28 11:11:16,909] Trial 3 finished with value: 1.3205266473999875 and parameters: {'subsample': 1, 'n_estimators': 307, 'learning_rate': 0.03559648166113955}. Best is trial 3 with value: 1.3205266473999875.\n",
      "[I 2023-11-28 11:11:17,184] Trial 4 finished with value: 1.3221885640452626 and parameters: {'subsample': 0.9, 'n_estimators': 369, 'learning_rate': 0.030055535643413803}. Best is trial 3 with value: 1.3205266473999875.\n",
      "[I 2023-11-28 11:11:17,359] Trial 5 finished with value: 1.318695327966381 and parameters: {'subsample': 1, 'n_estimators': 358, 'learning_rate': 0.03355036199522812}. Best is trial 5 with value: 1.318695327966381.\n",
      "[I 2023-11-28 11:11:17,523] Trial 6 finished with value: 1.3187478938424821 and parameters: {'subsample': 1, 'n_estimators': 350, 'learning_rate': 0.04007612805882925}. Best is trial 5 with value: 1.318695327966381.\n",
      "[I 2023-11-28 11:11:17,692] Trial 7 finished with value: 1.3160167415202964 and parameters: {'subsample': 0.8, 'n_estimators': 363, 'learning_rate': 0.04034960064997255}. Best is trial 7 with value: 1.3160167415202964.\n",
      "[I 2023-11-28 11:11:17,803] Trial 8 finished with value: 1.3195097663462014 and parameters: {'subsample': 0.8, 'n_estimators': 223, 'learning_rate': 0.043142721338575316}. Best is trial 7 with value: 1.3160167415202964.\n",
      "[I 2023-11-28 11:11:17,939] Trial 9 finished with value: 1.318567010779372 and parameters: {'subsample': 0.85, 'n_estimators': 288, 'learning_rate': 0.04968267457316443}. Best is trial 7 with value: 1.3160167415202964.\n",
      "[I 2023-11-28 11:11:18,156] Trial 10 finished with value: 1.3149818878651751 and parameters: {'subsample': 0.8, 'n_estimators': 397, 'learning_rate': 0.03787823246766331}. Best is trial 10 with value: 1.3149818878651751.\n",
      "[I 2023-11-28 11:11:18,373] Trial 11 finished with value: 1.314034628543416 and parameters: {'subsample': 0.8, 'n_estimators': 395, 'learning_rate': 0.0381805162300886}. Best is trial 11 with value: 1.314034628543416.\n",
      "[I 2023-11-28 11:11:18,577] Trial 12 finished with value: 1.3155081092012468 and parameters: {'subsample': 0.8, 'n_estimators': 399, 'learning_rate': 0.03707827430197907}. Best is trial 11 with value: 1.314034628543416.\n",
      "[I 2023-11-28 11:11:18,784] Trial 13 finished with value: 1.3139602144777993 and parameters: {'subsample': 0.8, 'n_estimators': 398, 'learning_rate': 0.037895846956962874}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:18,950] Trial 14 finished with value: 1.3246242245050075 and parameters: {'subsample': 0.85, 'n_estimators': 315, 'learning_rate': 0.03814814550159816}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:19,174] Trial 15 finished with value: 1.3271971097404573 and parameters: {'subsample': 0.8, 'n_estimators': 242, 'learning_rate': 0.03236868037907181}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:19,396] Trial 16 finished with value: 1.3174606289647524 and parameters: {'subsample': 0.9, 'n_estimators': 383, 'learning_rate': 0.0352953370408681}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:19,603] Trial 17 finished with value: 1.3161315513701564 and parameters: {'subsample': 0.8, 'n_estimators': 335, 'learning_rate': 0.04161969721011542}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:19,842] Trial 18 finished with value: 1.3191255290145627 and parameters: {'subsample': 0.8, 'n_estimators': 328, 'learning_rate': 0.03845772567535147}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:20,008] Trial 19 finished with value: 1.3188212067649234 and parameters: {'subsample': 0.95, 'n_estimators': 265, 'learning_rate': 0.03611204696046623}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:20,208] Trial 20 finished with value: 1.3143002984968692 and parameters: {'subsample': 0.9, 'n_estimators': 386, 'learning_rate': 0.038957509722699055}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:20,411] Trial 21 finished with value: 1.318810101914343 and parameters: {'subsample': 0.9, 'n_estimators': 380, 'learning_rate': 0.038767822212732936}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:20,691] Trial 22 finished with value: 1.3212478395915532 and parameters: {'subsample': 0.9, 'n_estimators': 383, 'learning_rate': 0.037023018857882305}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:20,894] Trial 23 finished with value: 1.3174069220140512 and parameters: {'subsample': 0.9, 'n_estimators': 398, 'learning_rate': 0.04010305939756009}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:21,066] Trial 24 finished with value: 1.3173757984420413 and parameters: {'subsample': 0.85, 'n_estimators': 339, 'learning_rate': 0.03389254221349872}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:21,266] Trial 25 finished with value: 1.3180267806497568 and parameters: {'subsample': 0.9, 'n_estimators': 376, 'learning_rate': 0.03680562133418818}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:21,469] Trial 26 finished with value: 1.3193410947398887 and parameters: {'subsample': 0.8, 'n_estimators': 400, 'learning_rate': 0.04159061492125608}. Best is trial 13 with value: 1.3139602144777993.\n",
      "[I 2023-11-28 11:11:21,666] Trial 27 finished with value: 1.311972347430677 and parameters: {'subsample': 0.8, 'n_estimators': 383, 'learning_rate': 0.03944923198950574}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:21,878] Trial 28 finished with value: 1.316577038788397 and parameters: {'subsample': 0.8, 'n_estimators': 371, 'learning_rate': 0.03681032543166738}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:22,022] Trial 29 finished with value: 1.323955378024021 and parameters: {'subsample': 0.8, 'n_estimators': 260, 'learning_rate': 0.03480072983111303}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:22,196] Trial 30 finished with value: 1.3193878093451874 and parameters: {'subsample': 0.8, 'n_estimators': 321, 'learning_rate': 0.035452251976123034}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:22,416] Trial 31 finished with value: 1.3179204345318136 and parameters: {'subsample': 0.8, 'n_estimators': 387, 'learning_rate': 0.03908772285236192}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:22,596] Trial 32 finished with value: 1.32002066348722 and parameters: {'subsample': 0.95, 'n_estimators': 347, 'learning_rate': 0.03894033739786822}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:22,800] Trial 33 finished with value: 1.313534338397418 and parameters: {'subsample': 0.8, 'n_estimators': 389, 'learning_rate': 0.037893266172199326}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:22,988] Trial 34 finished with value: 1.3145203474611202 and parameters: {'subsample': 0.8, 'n_estimators': 367, 'learning_rate': 0.037831935090210905}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:23,233] Trial 35 finished with value: 1.316854497114539 and parameters: {'subsample': 0.8, 'n_estimators': 393, 'learning_rate': 0.040991239213556976}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:23,390] Trial 36 finished with value: 1.3173312740776737 and parameters: {'subsample': 1, 'n_estimators': 296, 'learning_rate': 0.04253711517108648}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:23,571] Trial 37 finished with value: 1.320883677016092 and parameters: {'subsample': 0.8, 'n_estimators': 359, 'learning_rate': 0.039816112841359635}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:23,767] Trial 38 finished with value: 1.3179142026417932 and parameters: {'subsample': 0.95, 'n_estimators': 373, 'learning_rate': 0.03616631912591383}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:23,942] Trial 39 finished with value: 1.316944781357153 and parameters: {'subsample': 0.8, 'n_estimators': 343, 'learning_rate': 0.03456886113653672}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:24,138] Trial 40 finished with value: 1.3160196851778212 and parameters: {'subsample': 1, 'n_estimators': 360, 'learning_rate': 0.03969485683262247}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:24,344] Trial 41 finished with value: 1.3170700241969981 and parameters: {'subsample': 0.9, 'n_estimators': 386, 'learning_rate': 0.037525200550253775}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:24,544] Trial 42 finished with value: 1.3190253647748615 and parameters: {'subsample': 0.8, 'n_estimators': 389, 'learning_rate': 0.03873084094219443}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:24,740] Trial 43 finished with value: 1.3163447531372465 and parameters: {'subsample': 0.85, 'n_estimators': 377, 'learning_rate': 0.04085615051805556}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:24,942] Trial 44 finished with value: 1.3207930706351612 and parameters: {'subsample': 0.8, 'n_estimators': 371, 'learning_rate': 0.03942425429875281}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:25,165] Trial 45 finished with value: 1.3171149710494534 and parameters: {'subsample': 0.9, 'n_estimators': 355, 'learning_rate': 0.03810737078879286}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:25,451] Trial 46 finished with value: 1.3197189170221408 and parameters: {'subsample': 1, 'n_estimators': 386, 'learning_rate': 0.03642525232604472}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:25,668] Trial 47 finished with value: 1.3171813341351424 and parameters: {'subsample': 0.8, 'n_estimators': 392, 'learning_rate': 0.03747204502846955}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:25,849] Trial 48 finished with value: 1.320013418676622 and parameters: {'subsample': 0.8, 'n_estimators': 362, 'learning_rate': 0.04036804293496603}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:25,969] Trial 49 finished with value: 1.3245678816449071 and parameters: {'subsample': 0.95, 'n_estimators': 206, 'learning_rate': 0.03943583067496239}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:26,218] Trial 50 finished with value: 1.3150324519834018 and parameters: {'subsample': 0.85, 'n_estimators': 400, 'learning_rate': 0.035969314922327966}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:26,413] Trial 51 finished with value: 1.318335724674492 and parameters: {'subsample': 0.8, 'n_estimators': 367, 'learning_rate': 0.037855890686685316}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:26,615] Trial 52 finished with value: 1.3181928221845622 and parameters: {'subsample': 0.8, 'n_estimators': 379, 'learning_rate': 0.03786311787366656}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:26,825] Trial 53 finished with value: 1.315601632788656 and parameters: {'subsample': 0.8, 'n_estimators': 392, 'learning_rate': 0.038390333507268296}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:27,023] Trial 54 finished with value: 1.3152177281225816 and parameters: {'subsample': 0.8, 'n_estimators': 368, 'learning_rate': 0.037365171123225266}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:27,210] Trial 55 finished with value: 1.3168501019428067 and parameters: {'subsample': 0.9, 'n_estimators': 352, 'learning_rate': 0.038699177094400676}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:27,423] Trial 56 finished with value: 1.3136950822439328 and parameters: {'subsample': 0.8, 'n_estimators': 380, 'learning_rate': 0.03572480996677883}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:27,641] Trial 57 finished with value: 1.3157436561653117 and parameters: {'subsample': 0.8, 'n_estimators': 380, 'learning_rate': 0.03663419670920263}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:27,884] Trial 58 finished with value: 1.3200720050885668 and parameters: {'subsample': 0.9, 'n_estimators': 393, 'learning_rate': 0.03512785955159303}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:28,076] Trial 59 finished with value: 1.3239681637371241 and parameters: {'subsample': 0.8, 'n_estimators': 333, 'learning_rate': 0.035623940931125246}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:28,326] Trial 60 finished with value: 1.3183195559082994 and parameters: {'subsample': 0.8, 'n_estimators': 385, 'learning_rate': 0.03694402109660225}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:28,526] Trial 61 finished with value: 1.3209207798985951 and parameters: {'subsample': 0.8, 'n_estimators': 366, 'learning_rate': 0.03815965445833983}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:28,745] Trial 62 finished with value: 1.3176043749896738 and parameters: {'subsample': 0.8, 'n_estimators': 376, 'learning_rate': 0.0375662525762018}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:28,955] Trial 63 finished with value: 1.3134435933587312 and parameters: {'subsample': 0.8, 'n_estimators': 395, 'learning_rate': 0.039080469653343684}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:29,164] Trial 64 finished with value: 1.3184450099669838 and parameters: {'subsample': 0.8, 'n_estimators': 395, 'learning_rate': 0.03885821521015665}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:29,399] Trial 65 finished with value: 1.317670955572573 and parameters: {'subsample': 0.8, 'n_estimators': 399, 'learning_rate': 0.03941438436252087}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:29,599] Trial 66 finished with value: 1.3199221138313522 and parameters: {'subsample': 0.85, 'n_estimators': 383, 'learning_rate': 0.04020898383423597}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:29,801] Trial 67 finished with value: 1.318711310851747 and parameters: {'subsample': 0.9, 'n_estimators': 390, 'learning_rate': 0.036453804654681635}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:29,999] Trial 68 finished with value: 1.319315563774309 and parameters: {'subsample': 0.8, 'n_estimators': 375, 'learning_rate': 0.039153207465026256}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:30,166] Trial 69 finished with value: 1.3193494633134049 and parameters: {'subsample': 1, 'n_estimators': 307, 'learning_rate': 0.03709102215131626}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:30,304] Trial 70 finished with value: 1.318790324655849 and parameters: {'subsample': 0.95, 'n_estimators': 236, 'learning_rate': 0.03824158922887356}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:30,535] Trial 71 finished with value: 1.3158773074894536 and parameters: {'subsample': 0.8, 'n_estimators': 400, 'learning_rate': 0.03844002306083504}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:30,826] Trial 72 finished with value: 1.3173510648975757 and parameters: {'subsample': 0.8, 'n_estimators': 383, 'learning_rate': 0.03598014967147322}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:31,050] Trial 73 finished with value: 1.3143462510080448 and parameters: {'subsample': 0.8, 'n_estimators': 390, 'learning_rate': 0.037359393502420186}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:31,257] Trial 74 finished with value: 1.3178514259561875 and parameters: {'subsample': 0.8, 'n_estimators': 389, 'learning_rate': 0.0401250016299494}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:31,468] Trial 75 finished with value: 1.3200480705381017 and parameters: {'subsample': 0.8, 'n_estimators': 394, 'learning_rate': 0.03433090535047338}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:31,689] Trial 76 finished with value: 1.3161939502133173 and parameters: {'subsample': 0.8, 'n_estimators': 380, 'learning_rate': 0.03717588361859031}. Best is trial 27 with value: 1.311972347430677.\n",
      "[I 2023-11-28 11:11:31,897] Trial 77 finished with value: 1.3090998712297572 and parameters: {'subsample': 0.8, 'n_estimators': 388, 'learning_rate': 0.038863229772208976}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:32,050] Trial 78 finished with value: 1.3172309338359416 and parameters: {'subsample': 0.9, 'n_estimators': 282, 'learning_rate': 0.039692543711813265}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:32,248] Trial 79 finished with value: 1.3120231829794682 and parameters: {'subsample': 0.8, 'n_estimators': 373, 'learning_rate': 0.03891418548052117}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:32,451] Trial 80 finished with value: 1.3197400888936939 and parameters: {'subsample': 0.8, 'n_estimators': 370, 'learning_rate': 0.04070074700448815}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:32,650] Trial 81 finished with value: 1.3190920840602383 and parameters: {'subsample': 0.8, 'n_estimators': 375, 'learning_rate': 0.03913689674239011}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:32,859] Trial 82 finished with value: 1.3198278647747654 and parameters: {'subsample': 0.8, 'n_estimators': 396, 'learning_rate': 0.03861431132487903}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:33,063] Trial 83 finished with value: 1.3134297655000056 and parameters: {'subsample': 0.8, 'n_estimators': 386, 'learning_rate': 0.03985517191309926}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:33,273] Trial 84 finished with value: 1.3166232358240075 and parameters: {'subsample': 0.8, 'n_estimators': 381, 'learning_rate': 0.0398830131315155}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:33,484] Trial 85 finished with value: 1.321735023516027 and parameters: {'subsample': 0.8, 'n_estimators': 386, 'learning_rate': 0.04145931545252125}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:33,670] Trial 86 finished with value: 1.317389873988178 and parameters: {'subsample': 0.8, 'n_estimators': 362, 'learning_rate': 0.03788677043683094}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:33,887] Trial 87 finished with value: 1.3157204871980486 and parameters: {'subsample': 0.8, 'n_estimators': 397, 'learning_rate': 0.039399472470289076}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:34,106] Trial 88 finished with value: 1.3203003667074216 and parameters: {'subsample': 0.8, 'n_estimators': 347, 'learning_rate': 0.040579640711063465}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:34,294] Trial 89 finished with value: 1.3201059746063284 and parameters: {'subsample': 1, 'n_estimators': 269, 'learning_rate': 0.04119388846907753}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:34,505] Trial 90 finished with value: 1.3197166230611448 and parameters: {'subsample': 0.8, 'n_estimators': 389, 'learning_rate': 0.0399759528362192}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:34,802] Trial 91 finished with value: 1.32121504801225 and parameters: {'subsample': 0.85, 'n_estimators': 373, 'learning_rate': 0.03900545124660275}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:35,058] Trial 92 finished with value: 1.314251637964523 and parameters: {'subsample': 0.8, 'n_estimators': 385, 'learning_rate': 0.038472271844146366}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:35,261] Trial 93 finished with value: 1.3170482315298253 and parameters: {'subsample': 0.8, 'n_estimators': 379, 'learning_rate': 0.038574691991200505}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:35,473] Trial 94 finished with value: 1.3189670815401122 and parameters: {'subsample': 0.8, 'n_estimators': 394, 'learning_rate': 0.03670420196160937}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:35,698] Trial 95 finished with value: 1.323273374176753 and parameters: {'subsample': 0.8, 'n_estimators': 384, 'learning_rate': 0.03814680570744838}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:35,879] Trial 96 finished with value: 1.3182737287430053 and parameters: {'subsample': 0.95, 'n_estimators': 356, 'learning_rate': 0.037803404310158495}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:36,113] Trial 97 finished with value: 1.3168978296198766 and parameters: {'subsample': 0.8, 'n_estimators': 388, 'learning_rate': 0.03956842663281004}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:36,382] Trial 98 finished with value: 1.3169289992727236 and parameters: {'subsample': 0.8, 'n_estimators': 365, 'learning_rate': 0.04040006493354736}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:36,616] Trial 99 finished with value: 1.3183881825567596 and parameters: {'subsample': 0.8, 'n_estimators': 400, 'learning_rate': 0.03878572835619343}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:36,813] Trial 100 finished with value: 1.31717769910977 and parameters: {'subsample': 0.8, 'n_estimators': 371, 'learning_rate': 0.03831732228964234}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:37,025] Trial 101 finished with value: 1.3222368041512695 and parameters: {'subsample': 0.9, 'n_estimators': 395, 'learning_rate': 0.03911135535280986}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:37,232] Trial 102 finished with value: 1.315857139816637 and parameters: {'subsample': 0.8, 'n_estimators': 378, 'learning_rate': 0.03762619522050552}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:37,455] Trial 103 finished with value: 1.314382036959065 and parameters: {'subsample': 0.9, 'n_estimators': 385, 'learning_rate': 0.039577792857478734}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:37,662] Trial 104 finished with value: 1.3139905217852068 and parameters: {'subsample': 0.8, 'n_estimators': 393, 'learning_rate': 0.03846069713971505}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:37,883] Trial 105 finished with value: 1.31602876440523 and parameters: {'subsample': 0.8, 'n_estimators': 391, 'learning_rate': 0.037176141927509246}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:38,100] Trial 106 finished with value: 1.3175570579502784 and parameters: {'subsample': 0.8, 'n_estimators': 397, 'learning_rate': 0.03845418598310249}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:38,402] Trial 107 finished with value: 1.3170393219688337 and parameters: {'subsample': 0.8, 'n_estimators': 383, 'learning_rate': 0.04002502278898072}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:38,728] Trial 108 finished with value: 1.3209731247646082 and parameters: {'subsample': 0.8, 'n_estimators': 375, 'learning_rate': 0.03808780954897077}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:38,935] Trial 109 finished with value: 1.3169687279920532 and parameters: {'subsample': 0.8, 'n_estimators': 392, 'learning_rate': 0.037540528010641734}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:39,162] Trial 110 finished with value: 1.3158092494170026 and parameters: {'subsample': 0.8, 'n_estimators': 387, 'learning_rate': 0.03915744029648581}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:39,374] Trial 111 finished with value: 1.3181642049153617 and parameters: {'subsample': 1, 'n_estimators': 380, 'learning_rate': 0.03877801715127213}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:39,601] Trial 112 finished with value: 1.3153684472138647 and parameters: {'subsample': 0.8, 'n_estimators': 391, 'learning_rate': 0.03686752718150234}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:39,828] Trial 113 finished with value: 1.3200547731839347 and parameters: {'subsample': 0.85, 'n_estimators': 396, 'learning_rate': 0.039333642875052484}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:40,048] Trial 114 finished with value: 1.3204714315636994 and parameters: {'subsample': 0.95, 'n_estimators': 387, 'learning_rate': 0.03803933954066745}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:40,356] Trial 115 finished with value: 1.3158704057837403 and parameters: {'subsample': 0.8, 'n_estimators': 382, 'learning_rate': 0.03974172167909438}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:40,582] Trial 116 finished with value: 1.3148877277918236 and parameters: {'subsample': 0.9, 'n_estimators': 400, 'learning_rate': 0.038833818345593185}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:40,825] Trial 117 finished with value: 1.315780481095762 and parameters: {'subsample': 0.8, 'n_estimators': 377, 'learning_rate': 0.04038552488886476}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:41,025] Trial 118 finished with value: 1.3158791479312244 and parameters: {'subsample': 0.8, 'n_estimators': 371, 'learning_rate': 0.03641642416231802}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:41,321] Trial 119 finished with value: 1.3170880504695268 and parameters: {'subsample': 0.8, 'n_estimators': 392, 'learning_rate': 0.040983103711234384}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:41,534] Trial 120 finished with value: 1.3122471445987216 and parameters: {'subsample': 0.8, 'n_estimators': 386, 'learning_rate': 0.03767858668392087}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:41,834] Trial 121 finished with value: 1.3197658356256374 and parameters: {'subsample': 0.8, 'n_estimators': 387, 'learning_rate': 0.038423195490701126}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:42,066] Trial 122 finished with value: 1.320809396826468 and parameters: {'subsample': 0.8, 'n_estimators': 383, 'learning_rate': 0.03922525875809218}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:42,301] Trial 123 finished with value: 1.3176060068504378 and parameters: {'subsample': 0.8, 'n_estimators': 395, 'learning_rate': 0.03763798342603876}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:42,527] Trial 124 finished with value: 1.3159498073538805 and parameters: {'subsample': 0.8, 'n_estimators': 390, 'learning_rate': 0.03718801510128185}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:42,725] Trial 125 finished with value: 1.318060991400684 and parameters: {'subsample': 0.8, 'n_estimators': 377, 'learning_rate': 0.03802244886688422}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:42,893] Trial 126 finished with value: 1.3212067748434322 and parameters: {'subsample': 0.8, 'n_estimators': 319, 'learning_rate': 0.03871828206026936}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:43,099] Trial 127 finished with value: 1.3175034162889285 and parameters: {'subsample': 0.8, 'n_estimators': 385, 'learning_rate': 0.035819522253328205}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:43,312] Trial 128 finished with value: 1.3183601505604632 and parameters: {'subsample': 0.9, 'n_estimators': 373, 'learning_rate': 0.03626823699746191}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:43,520] Trial 129 finished with value: 1.3156708754868833 and parameters: {'subsample': 0.8, 'n_estimators': 396, 'learning_rate': 0.037661836067209596}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:43,732] Trial 130 finished with value: 1.3199066538975774 and parameters: {'subsample': 0.8, 'n_estimators': 380, 'learning_rate': 0.03982869478328544}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:43,967] Trial 131 finished with value: 1.3175422357563822 and parameters: {'subsample': 0.8, 'n_estimators': 390, 'learning_rate': 0.03728990359648511}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:44,196] Trial 132 finished with value: 1.315916063235503 and parameters: {'subsample': 0.8, 'n_estimators': 389, 'learning_rate': 0.03848834833070027}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:44,528] Trial 133 finished with value: 1.3168357562719322 and parameters: {'subsample': 0.8, 'n_estimators': 395, 'learning_rate': 0.038283705673849}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:44,777] Trial 134 finished with value: 1.319213434306771 and parameters: {'subsample': 0.8, 'n_estimators': 368, 'learning_rate': 0.036862208139826595}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:45,033] Trial 135 finished with value: 1.317373779541232 and parameters: {'subsample': 0.8, 'n_estimators': 400, 'learning_rate': 0.03896474619036859}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:45,341] Trial 136 finished with value: 1.319465423423525 and parameters: {'subsample': 1, 'n_estimators': 384, 'learning_rate': 0.03555329678400308}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:45,508] Trial 137 finished with value: 1.3160920898035797 and parameters: {'subsample': 0.85, 'n_estimators': 296, 'learning_rate': 0.037350784367548226}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:45,718] Trial 138 finished with value: 1.31519351599553 and parameters: {'subsample': 0.8, 'n_estimators': 393, 'learning_rate': 0.037878752507564666}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:45,933] Trial 139 finished with value: 1.3211156295928819 and parameters: {'subsample': 0.95, 'n_estimators': 381, 'learning_rate': 0.03942474276157719}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:46,160] Trial 140 finished with value: 1.3193126344780832 and parameters: {'subsample': 0.8, 'n_estimators': 387, 'learning_rate': 0.038998090485710374}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:46,392] Trial 141 finished with value: 1.3173225812692926 and parameters: {'subsample': 0.9, 'n_estimators': 386, 'learning_rate': 0.039652326631414915}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:46,643] Trial 142 finished with value: 1.318177314554371 and parameters: {'subsample': 0.9, 'n_estimators': 391, 'learning_rate': 0.04027716442420961}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:46,840] Trial 143 finished with value: 1.3184061517858443 and parameters: {'subsample': 0.9, 'n_estimators': 249, 'learning_rate': 0.038487745501922625}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:47,126] Trial 144 finished with value: 1.3165692279140673 and parameters: {'subsample': 0.9, 'n_estimators': 378, 'learning_rate': 0.039457707757638204}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:47,485] Trial 145 finished with value: 1.3191530811959946 and parameters: {'subsample': 0.9, 'n_estimators': 385, 'learning_rate': 0.037944051096354486}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:47,743] Trial 146 finished with value: 1.3144954691229767 and parameters: {'subsample': 0.8, 'n_estimators': 397, 'learning_rate': 0.03996094668160645}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:48,049] Trial 147 finished with value: 1.3117884924669192 and parameters: {'subsample': 0.8, 'n_estimators': 374, 'learning_rate': 0.038813392256667335}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:48,278] Trial 148 finished with value: 1.3177441046385483 and parameters: {'subsample': 0.8, 'n_estimators': 375, 'learning_rate': 0.036757878635237586}. Best is trial 77 with value: 1.3090998712297572.\n",
      "[I 2023-11-28 11:11:48,422] Trial 149 finished with value: 1.322177193653793 and parameters: {'subsample': 0.8, 'n_estimators': 205, 'learning_rate': 0.03868228193227887}. Best is trial 77 with value: 1.3090998712297572.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'n_estimators': 388, 'learning_rate': 0.038863229772208976}\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 447\n",
      "[LightGBM] [Info] Number of data points in the train set: 7784, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 3.371274\n",
      "농업경영체별 평가지표 결과\n",
      "MAE: 1.24\n",
      "MSE: 2.98\n",
      "RMSE: 1.72\n",
      "RMSPE: 127.16%\n",
      "----------------------------------------------------------------------------------------------------\n",
      "배정신청인원 10명 이상 시군구 단위 평가지표\n",
      "MAE: 7.91\n",
      "MSE: 129.02\n",
      "RMSE: 11.36\n",
      "RMSPE: 20.72%\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    params={\n",
    "        'n_jobs':-1,\n",
    "        'objective':'regression',\n",
    "        'verbosity':0,\n",
    "        'subsample': trial.suggest_categorical('subsample',[0.8,0.85,0.90,0.95,1]),\n",
    "        'n_estimators': trial.suggest_int('n_estimators',200,400),\n",
    "        'learning_rate': trial.suggest_float('learning_rate',0.03,0.05)\n",
    "    }\n",
    "    # 학습 모델 생성\n",
    "    model_reg= LGBMRegressor(**params)\n",
    "    \n",
    "    #트레인 셋 학습\n",
    "    model_reg.fit(X_train,Y_train)\n",
    "    \n",
    "    #검증 데이터 셋으로 모델 검증\n",
    "    score = mean_absolute_error(model_reg.predict(X_valid), Y_valid)\n",
    "    return score\n",
    "\n",
    "study=optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=150)\n",
    "\n",
    "# 최적화된 파라미터 값 확인\n",
    "best_params = study.best_params\n",
    "print(best_params)\n",
    "\n",
    "model_reg =  LGBMRegressor(**best_params)\n",
    "model_reg.fit(X_train,Y_train)\n",
    "\n",
    "#예측값 \n",
    "pred=model_reg.predict(X_test)\n",
    "# 인원 수 예측이기에 예측된 결과에 반올림 적용\n",
    "pred=pd.DataFrame(pred,columns=['예측값'])\n",
    "#반올림\n",
    "pred['예측값']=round(pred['예측값'],0)\n",
    "#평가지표\n",
    "print('농업경영체별 평가지표 결과')\n",
    "Evaluation_metric(Y_test,pred=pred['예측값'])\n",
    "print('-'*100)\n",
    "\n",
    "test_index=X_test.index.tolist()\n",
    "data_test=data_real.loc[test_index]\n",
    "data_test=data_test.reset_index()\n",
    "data_test.drop(columns=['index'],inplace=True)\n",
    "#예측값\n",
    "data_test['predict']=pred\n",
    "result=data_test.groupby(['지자체명_시도','지자체명_시군구'])[['합계','predict']].sum().reset_index()\n",
    "result_1=result.query('합계>10')\n",
    "print('배정신청인원 10명 이상 시군구 단위 평가지표')\n",
    "Evaluation_metric(result_1['합계'],pred=result_1['predict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f99605-4e87-430f-883a-21ef9352e8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
